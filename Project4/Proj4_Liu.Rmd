
# This exercise involves the Boston housing data set in ISLR2. Assume that we are interested in median home values, medv.
```{r}
library(ISLR2)
data("Boston")
```

## 1. Examine medv as a function of crim, zn and indus in a multiple linear regression
```{r}
model_multi <- lm(Boston$medv~Boston$crim + Boston$zn + Boston$indus)
```

### A. Identify predictors significant at 5% level.
- $F=\dfrac{(SS_Y-RSS)/(p-1)}{RSS/(n-p)}$
```{r}
anova(model_multi)
F_multi<-((sum(anova(model_multi)[,2])-anova(model_multi)[4,2])/(4-1))/
  (anova(model_multi)[4,2]/(dim(Boston)[1]-4))
summary(model_multi)
```
### B. List the hypotheses tested in 1.A and their conclusions
- $H_0: \beta_{crim}=\beta_{zn}=\beta{indus}=0$.
- p-value: < 2.2e-16; We reject $H_0$.

### C. What do the estimated regression coefficients in 1.A mean in lay terms? Do they make sense?
```{r}
coef(model_multi)
```
- slopes; Yes.

### D. Construct 95% confidence intervals for `$\beta_{crim}$`, `$\beta_{zn}$` and `$\beta_{indus}$`. How do the confidence intervals correspond to 1.A and 1.B?
```{r}
m_multi_con <- confint(model_multi,level = 0.95)
m_multi_con
```
- From lecture note p.37, the 95% confidence interval of $\beta_1$ is:\
$\hat{\beta}_1 \pm t^{\alpha/2}_{n-p} \times SE(\hat{\beta}_1)$. (不在这个区间$[2.5%, 97.5%]$说明p值小于0.05)

### E. Calculate the R2 and R2 adj by hand and report whether this matches the R2 and R2 adj from the output and whey mean?
```{r}
Boston$pre_medv = coef(model_multi)[1]+coef(model_multi)[2]*Boston$crim+coef(model_multi)[3]*Boston$zn+coef(model_multi)[4]*Boston$indus 
Boston$error = Boston$medv - Boston$pre_medv
RSS <- sum(Boston$error^2)
SS_Y <- sum((Boston$medv - mean(Boston$medv))^2)
R_2 <- 1- (RSS/SS_Y)
R_2_adj <- 1 - ((1-R_2)*(dim(Boston)[1]-1))/(dim(Boston)[1]-4)
```
- No, In this case, R^2 isn't match with R^2 adj. R-squared measures how well the model fits the observed data and takes values ranging from $0$ to $1$, and the adjusted R-squared takes into account the number of independent variables in the model, so it penalizes excess independent variables to avoid overfitting, ranging from $-\infty$ to $1$.


## 2.Compare the model from #1 and a simple linear regression of medv as a function of zn. Which would you prefer?
```{r}
model_zn <- lm(Boston$medv~Boston$zn)
```

### A. Identify predictors significant at 5% level.
- $F=\dfrac{(SS_Y-RSS)/(p-1)}{RSS/(n-p)}$
```{r}
anova(model_zn)
F_zn<-((sum(anova(model_zn)[,2])-anova(model_zn)[2,2])/(2-1))/
  (anova(model_zn)[2,2]/(dim(Boston)[1]-2))
summary(model_zn)
```
### B. List the hypotheses tested in 1.A and their conclusions
- $H_0: \beta_{crim}=\beta_{zn}=\beta{indus}=0$.
- p-value: < 2.2e-16; We reject $H_0$.

### C. What do the estimated regression coefficients in 2.A mean in lay terms? Do they make sense?
```{r}
coef(model_zn)
```
- slopes; Yes.

### D. Construct 95% confidence intervals for `$\beta_{zn}$`. How do the confidence intervals correspond to 1.A and 1.B?
```{r}
m_zn_con <- confint(model_zn,level = 0.95)
m_zn_con
```
- From lecture note p.37, the 95% confidence interval of $\beta_1$ is:\
$\hat{\beta}_1 \pm t^{\alpha/2}_{n-p} \times SE(\hat{\beta}_1)$. (不在这个区间说明p值小于0.05)

### E. Calculate the R2 and R2 adj by hand and report whether this matches the R2 and R2 adj from the output and whey mean?
```{r}
Boston$pre_medv_zn = coef(model_zn)[1]+coef(model_zn)[2]*Boston$zn
Boston$error_zn = Boston$medv - Boston$pre_medv_zn
RSS_zn <- sum(Boston$error_zn^2)
SS_Y_zn <- sum((Boston$medv - mean(Boston$medv))^2)
R_2_zn <- 1- (RSS_zn/SS_Y_zn)
R_2_adj_zn <- 1 - ((1-R_2)*(dim(Boston)[1]-1))/(dim(Boston)[1]-4)
```
- Yes, In this case, R^2 matches with R2 adj, cause this is simple liner regression with one predictor.